{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "id": "7-VfxIfScAIw"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install yfinance"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ocGAu-8n4O_S",
    "outputId": "e35db8a1-b428-4921-f874-f0a381d1631b"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PoNti273bz7U"
   },
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "#Fin Data Sources\n",
    "import yfinance as yf\n",
    "import pandas_datareader as pdr\n",
    "\n",
    "#Data viz\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "\n",
    "import time\n",
    "from datetime import date\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Question 1: IPO Filings Web Scraping and Data Processing\n",
    "What's the total sum ($m) of 2023 filings that happened on Fridays?\n",
    "\n",
    "Re-use the [Code Snippet 1] example to get the data from web for this endpoint: https://stockanalysis.com/ipos/filings/ Convert the 'Filing Date' to datetime(), 'Shares Offered' to float64 (if '-' is encountered, populate with NaNs). Define a new field 'Avg_price' based on the \"Price Range\", which equals to NaN if no price is specified, to the price (if only one number is provided), or to the average of 2 prices (if a range is given). You may be inspired by the function extract_numbers() in [Code Snippet 4], or you can write your own function to \"parse\" a string. Define a column \"Shares_offered_value\", which equals to \"Shares Offered\" * \"Avg_price\" (when both columns are defined; otherwise, it's NaN)\n",
    "\n",
    "Find the total sum in $m (millions of USD, closest INTEGER number) for all filings during 2023, which happened on Fridays (Date.dt.dayofweek()==4). You should see 32 records in total, 25 of it is not null.\n",
    "\n",
    "(additional: you can read about S-1 IPO filing to understand the context)"
   ],
   "metadata": {
    "id": "bM5qRh05cO4c"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Re-use the [Code Snippet 1] example to get the data from web for this endpoint: https://stockanalysis.com/ipos/filings/\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
    "}\n",
    "\n",
    "url = 'https://stockanalysis.com/ipos/filings/'\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "filings_table = pd.read_html(response.text)\n",
    "df = filings_table[0]"
   ],
   "metadata": {
    "id": "bP86M34hcNNQ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Convert the 'Filing Date' to datetime(), 'Shares Offered' to float64 (if '-' is encountered, populate with NaNs).\n",
    "\n",
    "df['Filing Date'] = pd.to_datetime(df['Filing Date'], format=\"mixed\")\n",
    "df['Shares Offered'] = df['Shares Offered'].replace('-', np.NaN)\n",
    "df['Shares Offered'] = pd.to_numeric(df['Shares Offered']).astype(float)\n",
    "\n",
    "\n",
    "# Define a new field 'Avg_price' based on the \"Price Range\", which equals to NaN if no price is specified,\n",
    "# to the price (if only one number is provided), or to the average of 2 prices (if a range is given).\n",
    "# You may be inspired by the function extract_numbers() in [Code Snippet 4], or you can write your own function to \"parse\" a string.\n",
    "\n",
    "def set_avg_price(input_string):\n",
    "    temp = re.findall(r'\\d+.\\d+', input_string)\n",
    "    if temp == []:\n",
    "        return np.NaN\n",
    "    else:\n",
    "        r = 0\n",
    "        for i in temp:\n",
    "            r += float(i)\n",
    "        return (r / len(temp))\n",
    "\n",
    "\n",
    "# Define a column \"Shares_offered_value\", which equals to \"Shares Offered\" * \"Avg_price\" (when both columns are defined; otherwise, it's NaN)\n",
    "\n",
    "def set_shares_offered_value(shares_offered, avg_price):\n",
    "    series = pd.Series([shares_offered, avg_price])\n",
    "    if series.isnull().any().any():\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return shares_offered * avg_price\n",
    "\n",
    "\n",
    "df['Avg_price'] = df['Price Range'].apply(set_avg_price)\n",
    "df[\"Shares_offered_value\"] = df.apply(lambda x: set_shares_offered_value(x['Shares Offered'], x['Avg_price']), axis=1)"
   ],
   "metadata": {
    "id": "_PNZE6TFe4lB"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Find the total sum in $m (millions of USD, closest INTEGER number) for all filings during 2023, which happened on Fridays (Date.dt.dayofweek()==4).\n",
    "# You should see 32 records in total, 25 of it is not null.\n",
    "\n",
    "fridays = df[(df[\"Filing Date\"].dt.year == 2023) & (df[\"Filing Date\"].dt.dayofweek == 4)]\n",
    "\n",
    "(fridays[\"Shares_offered_value\"].sum() / 1000000).round(0)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R9_ZVgioL1XQ",
    "outputId": "9f060575-6dad-45f4-ba37-79d1418f14c9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Question 2: IPOs \"Fixed days hold\" strategy\n",
    "Find the optimal number of days X (between 1 and 30), where 75% quantile growth is the highest?\n",
    "\n",
    "Reuse [Code Snippet 1] to retrieve the list of IPOs from 2023 and 2024 (from URLs: https://stockanalysis.com/ipos/2023/ and https://stockanalysis.com/ipos/2024/). Get all OHLCV daily prices for all stocks with an \"IPO date\" before March 1, 2024 (\"< 2024-03-01\") - 184 tickers (without 'RYZB'). Please remove 'RYZB', as it is no longer available on Yahoo Finance.\n",
    "\n",
    "Sometimes you may need to adjust the symbol name (e.g., 'IBAC' on stockanalysis.com -> 'IBACU' on Yahoo Finance) to locate OHLCV prices for all stocks. Also, you can see the ticker changes using this link. Some of the tickers (like 'DYCQ' and 'LEGT') were on the market less than 30 days (11 and 21 days, respectively). Let's leave them in the dataset; it just means that you couldn't hold them for more days than they were listed.\n",
    "\n",
    "Let's assume you managed to buy a new stock (listed on IPO) on the first day at the [Adj Close] price]. Your strategy is to hold for exactly X full days (where X is between 1 and 30) and sell at the \"Adj. Close\" price in X days (e.g., if X=1, you sell on the next day). Find X, when the 75% quantile growth (among 185 investments) is the highest.\n",
    "\n",
    "HINTs:\n",
    "\n",
    "You can generate 30 additional columns: growth_future_1d ... growth_future_30d, join that with the table of min_dates (first day when each stock has data on Yahoo Finance), and perform vector operations on the resulting dataset.\n",
    "You can use the DataFrame.describe() function to get mean, min, max, 25-50-75% quantiles.\n",
    "Additional:\n",
    "\n",
    "You can also ensure that the mean and 50th percentile (median) investment returns are negative for most X values, implying a wager for a \"lucky\" investor who might be in the top 25%.\n",
    "What's your recommendation: Do you suggest pursuing this strategy for an optimal X?"
   ],
   "metadata": {
    "id": "keaDGeUlra5K"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Reuse [Code Snippet 1] to retrieve the list of IPOs from 2023 and 2024 (from URLs: https://stockanalysis.com/ipos/2023/ and https://stockanalysis.com/ipos/2024/).\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
    "}\n",
    "\n",
    "url_2023 = 'https://stockanalysis.com/ipos/2023/'\n",
    "url_2024 = 'https://stockanalysis.com/ipos/2024/'\n",
    "\n",
    "\n",
    "def get_data(headers, url):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    filings_table = pd.read_html(response.text)\n",
    "    return filings_table[0]\n",
    "\n",
    "\n",
    "ipos_2023 = get_data(headers, url_2023)\n",
    "ipos_2024 = get_data(headers, url_2024)\n",
    "stacked_ipos_df = pd.concat([ipos_2023, ipos_2024], ignore_index=True)"
   ],
   "metadata": {
    "id": "u3ZKSAZMq_oH"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "stacked_ipos_df[stacked_ipos_df.Symbol.isin(['IBAC', 'BKHA'])]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "-najIjLx4yg6",
    "outputId": "4f0539b3-d94f-4520-d87c-2fcf8b7ca529"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# convert to datetime\n",
    "\n",
    "stacked_ipos_df['IPO Date'] = pd.to_datetime(stacked_ipos_df['IPO Date'])"
   ],
   "metadata": {
    "id": "mgaCV_tm5Fkt"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "TICKERS = [e for e in stacked_ipos_df[stacked_ipos_df['IPO Date'] < '2024-03-01'].Symbol.tolist()]\n",
    "len(TICKERS)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CUUrdlRY5cDd",
    "outputId": "d20cfaf1-255c-4d2d-b1e4-980007ba6831"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Sometimes you may need to adjust the symbol name (e.g., 'IBAC' on stockanalysis.com -> 'IBACU' on Yahoo Finance) to locate OHLCV prices for all stocks.\n",
    "# Also, you can see the ticker changes using this link. Some of the tickers (like 'DYCQ' and 'LEGT') were on the market less than 30 days (11 and 21 days, respectively).\n",
    "# Let's leave them in the dataset; it just means that you couldn't hold them for more days than they were listed.\n",
    "\n",
    "def correct_ticker(ticker: str):\n",
    "    match ticker:\n",
    "        case 'IBAC':\n",
    "            return 'IBACU'\n",
    "        case 'BKHA':\n",
    "            return 'BKHAU'\n",
    "        case 'PTHR':\n",
    "            return 'PTHRU'\n",
    "        case _:\n",
    "            return ticker"
   ],
   "metadata": {
    "id": "IGeuuWaf5-OQ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Get all OHLCV daily prices for all stocks with an \"IPO date\" before March 1, 2024 (\"< 2024-03-01\") - 184 tickers (without 'RYZB').\n",
    "# Please remove 'RYZB', as it is no longer available on Yahoo Finance.\n",
    "\n",
    "def get_stocks_df(TICKERS):\n",
    "    stocks_df = pd.DataFrame({'A': []})\n",
    "    print(stocks_df)\n",
    "\n",
    "    for i, ticker in enumerate(TICKERS):\n",
    "        if ticker == 'RYZB':\n",
    "            continue\n",
    "        ticker = correct_ticker(ticker)\n",
    "        print(f'Getting {ticker}')\n",
    "        print(i, ticker)\n",
    "\n",
    "        # work with stock prices\n",
    "        historyPrices = yf.download(tickers=ticker, period='max', interval='1d')\n",
    "\n",
    "        # generate column for historical prices that we want to predict\n",
    "        historyPrices['Ticker'] = ticker\n",
    "        historyPrices['Year'] = historyPrices.index.year\n",
    "        historyPrices['Month'] = historyPrices.index.month\n",
    "        historyPrices['Weekday'] = historyPrices.index.weekday\n",
    "        historyPrices['Date'] = historyPrices.index.date\n",
    "\n",
    "        # historical returns\n",
    "        for i in [1, 3, 7, 30, 90, 365]:\n",
    "            historyPrices['growth_' + str(i) + 'd'] = historyPrices['Adj Close'] / historyPrices['Adj Close'].shift(i)\n",
    "\n",
    "        historyPrices['growth_5d'] = historyPrices['Adj Close'].shift(-55) / historyPrices['Adj Close']\n",
    "\n",
    "        # Technical indicators\n",
    "        # SimpleMovinAverage 10 days and 20 days\n",
    "        historyPrices['SMA10'] = historyPrices['Adj Close'].rolling(window=10).mean()\n",
    "        historyPrices['SMA20'] = historyPrices['Adj Close'].rolling(window=20).mean()\n",
    "        historyPrices['growing_movin_average'] = np.where(historyPrices['SMA10'] > historyPrices['SMA20'], 1, 0)\n",
    "        historyPrices['high_minus_low_relative'] = (historyPrices.High - historyPrices.Low) / historyPrices['Adj Close']\n",
    "\n",
    "        # 30d rolling volatility\n",
    "        historyPrices['volatility'] = historyPrices['Adj Close'].rolling(window=30).std() * np.sqrt(252)\n",
    "\n",
    "        # what we wants to predict\n",
    "        historyPrices['is_positive_growth_5d_in_future'] = np.where(historyPrices['growth_5d'] > 1, 1, 0)\n",
    "\n",
    "        # sleep 1 sec between downloads - not to overload API server\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "        if stocks_df.empty:\n",
    "            stocks_df = historyPrices\n",
    "        else:\n",
    "            stocks_df = pd.concat([stocks_df, historyPrices], ignore_index=True)\n",
    "\n",
    "    return stocks_df"
   ],
   "metadata": {
    "id": "_Dp7o3hX7o7k"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "stocks_df = get_stocks_df(TICKERS)\n",
    "stocks_df.info()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k5FWnudRCbKJ",
    "outputId": "b3f43547-5d31-4310-e2a3-190f6aff22d2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "stocks_df.Ticker.nunique()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gR89M1iADIBs",
    "outputId": "25f06196-d89d-4c8a-83d4-c2ca6562ad71"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "stocks_df.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "F03jofTXDKu4",
    "outputId": "975eb4e6-8e6e-450e-c143-4e38e68966ff"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df = stocks_df.copy(deep=True)"
   ],
   "metadata": {
    "id": "SkrIXenrDSwJ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for i in range(30):\n",
    "    shift = i + 1\n",
    "    df[f'future_growth_' + str(shift) + '_d'] = df['Adj Close'].shift(-shift) / df['Adj Close']"
   ],
   "metadata": {
    "id": "EI4GL9k5DZlH"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# min_dates['Ticker'] - min_dates.index\n",
    "\n",
    "min_dates = pd.DataFrame(df.groupby('Ticker').Date.min())\n",
    "min_dates.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "iYC6LSHMEysX",
    "outputId": "58601115-d70f-408c-fe7d-0019efda789f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "min_dates.reset_index(inplace=True)\n",
    "min_dates"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "LP_BQGCKFoFh",
    "outputId": "84061dc8-c99d-4479-a68a-8d098e53b19d"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "merged = pd.merge(df, min_dates, on=['Date', 'Ticker'], how='inner')\n",
    "merged"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "MRC3CypOF5YT",
    "outputId": "0f52ccdf-f31f-40b2-c53c-b34b7654a508"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "KEYS = [k for k in merged.keys() if k.find('future_') == 0]\n",
    "KEYS"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OOFcMkfMGPq1",
    "outputId": "b160db14-952d-4114-ad56-068bb14e1d0d"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "merged[KEYS].describe().T"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 990
    },
    "id": "EkPf7gaiIO9d",
    "outputId": "3bfb256d-a6ff-46fc-e5d2-d16d61def0ee"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "merged[merged.future_growth_30_d > 9]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "id": "OWvD4Q3rIugi",
    "outputId": "b365f31d-15ea-4de8-f206-98ff965ea9df"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "merged[merged.future_growth_30_d > 9].Date"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LGeHYXCwJCyQ",
    "outputId": "c5516c28-82c0-49cf-ff24-bc1c683252e3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# interested in 75 % only\n",
    "dct = dict(merged[KEYS].describe().T['75%'])"
   ],
   "metadata": {
    "id": "wN2IkhT7JKfK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "future_growth = dct"
   ],
   "metadata": {
    "id": "j7dVe1UxJl7b"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "sorted_dict = dict(sorted(future_growth.items(), key=lambda item: item[1]))\n",
    "sorted_dict"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NTXfQPawJss-",
    "outputId": "962ec0bc-551d-4daa-d0f6-94ded2e7a339"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Find the optimal number of days X (between 1 and 30), where 75% quantile growth is the highest\n",
    "list(sorted_dict.keys())[-1]\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "1h5wmVkiJ-mp",
    "outputId": "18a8a81f-caa1-4455-a8e3-f1def5d2578d"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Question 3: Is Growth Concentrated in the Largest Stocks?\n",
    "Get the share of days (percentage as int) when Large Stocks outperform (growth_7d - growth over 7 periods back) the Largest stocks?\n",
    "\n",
    "Reuse [Code Snippet 7] to obtain OHLCV stats for 33 stocks for 10 full years of data (2014-01-01 to 2023-12-31). You'll need to download slightly more data (7 periods before 2014-01-01 to calculate the growth_7d for the first 6 days correctly):\n",
    "\n",
    "US_STOCKS = ['MSFT', 'AAPL', 'GOOG', 'NVDA', 'AMZN', 'META', 'BRK-B', 'LLY', 'AVGO','V', 'JPM']\n",
    "\n",
    "EU_STOCKS = ['NVO','MC.PA', 'ASML', 'RMS.PA', 'OR.PA', 'SAP', 'ACN', 'TTE', 'SIE.DE','IDEXY','CDI.PA']\n",
    "\n",
    "INDIA_STOCKS = ['RELIANCE.NS','TCS.NS','HDB','BHARTIARTL.NS','IBN','SBIN.NS','LICI.NS','INFY','ITC.NS','HINDUNILVR.NS','LT.NS']\n",
    "\n",
    "LARGEST_STOCKS = US_STOCKS + EU_STOCKS + INDIA_STOCKS\n",
    "\n",
    "Now let's add the top 12-22 stocks (as of end-April 2024):\n",
    "\n",
    "NEW_US = ['TSLA','WMT','XOM','UNH','MA','PG','JNJ','MRK','HD','COST','ORCL']\n",
    "\n",
    "NEW_EU = ['PRX.AS','AIR.PA','SU.PA','ETN','SNY','BUD','DTE.DE','ALV.DE','MDT','AI.PA','EL.PA']\n",
    "\n",
    "NEW_INDIA = ['BAJFINANCE.NS','MARUTI.NS','HCLTECH.NS','TATAMOTORS.NS','SUNPHARMA.NS','ONGC.NS','ADANIENT.NS','NTPC.NS','KOTAKBANK.NS','TITAN.NS']\n",
    "\n",
    "LARGE_STOCKS = NEW_EU + NEW_US + NEW_INDIA\n",
    "\n",
    "You should be able to obtain stats for 33 LARGEST STOCKS and 32 LARGE STOCKS (from the actual stats on Yahoo Finance)\n",
    "\n",
    "Calculate growth_7d for every stock and every day. Get the average daily growth_7d for the LARGEST_STOCKS group vs. the LARGE_STOCKS group.\n",
    "\n",
    "For example, for the first of data you should have:\n",
    "\n",
    "Date\tticker_category\tgrowth_7d\n",
    "2014-01-01\tLARGE\t1.011684\n",
    "2014-01-01\tLARGEST\t1.011797\n",
    "On that day, the LARGEST group was growing faster than LARGE one (new stocks).\n",
    "\n",
    "Calculate the number of days when the LARGE GROUP (new smaller stocks) outperforms the LARGEST GROUP, divide it by the total number of trading days (which should be 2595 days), and convert it to a percentage (closest INTEGER value). For example, if you find that 1700 out of 2595 days meet this condition, it means that 1700/2595 = 0.655, or approximately 66% of days, the LARGE stocks were growing faster than the LARGEST ones. This suggests that you should consider extending your dataset with more stocks to seek higher growth.\n",
    "\n",
    "HINT: you can use pandas.pivot_table() to \"flatten\" the table (LARGE and LARGEST growth_7d as columns)"
   ],
   "metadata": {
    "id": "jd6yLru06q2z"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Reuse [Code Snippet 7] to obtain OHLCV stats for 33 stocks for 10 full years of data (2014-01-01 to 2023-12-31).\n",
    "# You'll need to download slightly more data (7 periods before 2014-01-01 to calculate the growth_7d for the first 6 days correctly):\n",
    "\n",
    "US_STOCKS = ['MSFT', 'AAPL', 'GOOG', 'NVDA', 'AMZN', 'META', 'BRK-B', 'LLY', 'AVGO', 'V', 'JPM']\n",
    "\n",
    "EU_STOCKS = ['NVO', 'MC.PA', 'ASML', 'RMS.PA', 'OR.PA', 'SAP', 'ACN', 'TTE', 'SIE.DE', 'IDEXY', 'CDI.PA']\n",
    "\n",
    "INDIA_STOCKS = ['RELIANCE.NS', 'TCS.NS', 'HDB', 'BHARTIARTL.NS', 'IBN', 'SBIN.NS', 'LICI.NS', 'INFY', 'ITC.NS',\n",
    "                'HINDUNILVR.NS', 'LT.NS']\n",
    "\n",
    "PREVIOUS_STOCKS = US_STOCKS + EU_STOCKS + INDIA_STOCKS\n",
    "\n",
    "NEW_US = ['TSLA', 'WMT', 'XOM', 'UNH', 'MA', 'PG', 'JNJ', 'MRK', 'HD', 'COST', 'ORCL']\n",
    "\n",
    "NEW_EU = ['PRX.AS', 'AIR.PA', 'SU.PA', 'ETN', 'SNY', 'BUD', 'DTE.DE', 'ALV.DE', 'MDT', 'AI.PA', 'EL.PA']\n",
    "\n",
    "NEW_INDIA = ['BAJFINANCE.NS', 'MARUTI.NS', 'HCLTECH.NS', 'TATAMOTORS.NS', 'SUNPHARMA.NS', 'ONGC.NS', 'ADANIENT.NS',\n",
    "             'NTPC.NS', 'KOTAKBANK.NS', 'TITAN.NS']\n",
    "\n",
    "ADDITIONAL_STOCKS = NEW_US + NEW_EU + NEW_INDIA\n",
    "\n",
    "ALL_STOCKS = PREVIOUS_STOCKS + ADDITIONAL_STOCKS"
   ],
   "metadata": {
    "id": "_Saowp56BycH"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Reuse [Code Snippet 7] to obtain OHLCV stats for 33 stocks for 10 full years of data (2014-01-01 to 2023-12-31).\n",
    "\n",
    "full_df = get_stocks_df(ALL_STOCKS)"
   ],
   "metadata": {
    "id": "lTKr9N6bMw5d"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "full_df.info()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7PGMjo7uNKIx",
    "outputId": "ccdd7e3f-214d-49fc-df3f-f3c0c9799f69"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "full_df.Date = pd.to_datetime(full_df.Date)"
   ],
   "metadata": {
    "id": "DownKz3rNUHm"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "full_df_short = full_df[(full_df.Date > '2014-01-01') & (full_df.Date <= '2023-12-31')]\n",
    "full_df_short.info()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pg3Nl7MsNaT6",
    "outputId": "1a8b512a-c384-422b-c435-0ecf70661d10"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "full_df_short.Ticker.nunique()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BYgy6mtZOFTL",
    "outputId": "6e3ff7b7-1612-4878-cf93-f5a7d9365e8b"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "full_df_short.loc[:, 'ticker_category'] = full_df_short.Ticker.apply(lambda x: 'OLD' if x in PREVIOUS_STOCKS else 'NEW')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dNVm59TDOmWN",
    "outputId": "c06c916b-4b58-4d12-c29c-4231ca275d47"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# You should be able to obtain stats for 33 LARGEST STOCKS and 32 LARGE STOCKS (from the actual stats on Yahoo Finance)\n",
    "\n",
    "full_df_short.groupby('ticker_category').Ticker.nunique()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O5lY__AgO31t",
    "outputId": "a3d3be43-0bff-46d2-8d93-15b911bdd8ed"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "daily_avg_growth = full_df_short.groupby(['Date', 'ticker_category']).growth_7d.mean().reset_index()\n",
    "daily_avg_growth"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "FJuZtGKMPTN2",
    "outputId": "1d109e4c-9d30-45d2-9e3b-7363faa76cef"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "ticker_category       Date       NEW       OLD\n0               2014-01-02  1.004176  1.006333\n1               2014-01-03  1.002944  0.999152\n2               2014-01-06  0.997761  0.994203\n3               2014-01-07  0.994872  0.992509\n4               2014-01-08  0.992185  0.987730\n...                    ...       ...       ...\n2589            2023-12-22  1.003994  1.013788\n2590            2023-12-26  1.014441  1.014900\n2591            2023-12-27  1.004676  1.014155\n2592            2023-12-28  1.000828  1.008533\n2593            2023-12-29  1.000557  1.005337\n\n[2594 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>ticker_category</th>\n      <th>Date</th>\n      <th>NEW</th>\n      <th>OLD</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2014-01-02</td>\n      <td>1.004176</td>\n      <td>1.006333</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2014-01-03</td>\n      <td>1.002944</td>\n      <td>0.999152</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2014-01-06</td>\n      <td>0.997761</td>\n      <td>0.994203</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2014-01-07</td>\n      <td>0.994872</td>\n      <td>0.992509</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2014-01-08</td>\n      <td>0.992185</td>\n      <td>0.987730</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2589</th>\n      <td>2023-12-22</td>\n      <td>1.003994</td>\n      <td>1.013788</td>\n    </tr>\n    <tr>\n      <th>2590</th>\n      <td>2023-12-26</td>\n      <td>1.014441</td>\n      <td>1.014900</td>\n    </tr>\n    <tr>\n      <th>2591</th>\n      <td>2023-12-27</td>\n      <td>1.004676</td>\n      <td>1.014155</td>\n    </tr>\n    <tr>\n      <th>2592</th>\n      <td>2023-12-28</td>\n      <td>1.000828</td>\n      <td>1.008533</td>\n    </tr>\n    <tr>\n      <th>2593</th>\n      <td>2023-12-29</td>\n      <td>1.000557</td>\n      <td>1.005337</td>\n    </tr>\n  </tbody>\n</table>\n<p>2594 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate growth_7d for every stock and every day. \n",
    "\n",
    "pivot_table = daily_avg_growth.pivot_table(index=['Date'], columns='ticker_category', values='growth_7d', aggfunc='mean').reset_index()\n",
    "pivot_table"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T00:25:36.800587Z",
     "start_time": "2024-05-17T00:25:36.793170Z"
    }
   },
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "ticker_category       Date       NEW       OLD  more_new\n0               2014-01-02  1.004176  1.006333         0\n1               2014-01-03  1.002944  0.999152         1\n2               2014-01-06  0.997761  0.994203         1\n3               2014-01-07  0.994872  0.992509         1\n4               2014-01-08  0.992185  0.987730         1\n...                    ...       ...       ...       ...\n2589            2023-12-22  1.003994  1.013788         0\n2590            2023-12-26  1.014441  1.014900         0\n2591            2023-12-27  1.004676  1.014155         0\n2592            2023-12-28  1.000828  1.008533         0\n2593            2023-12-29  1.000557  1.005337         0\n\n[2594 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>ticker_category</th>\n      <th>Date</th>\n      <th>NEW</th>\n      <th>OLD</th>\n      <th>more_new</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2014-01-02</td>\n      <td>1.004176</td>\n      <td>1.006333</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2014-01-03</td>\n      <td>1.002944</td>\n      <td>0.999152</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2014-01-06</td>\n      <td>0.997761</td>\n      <td>0.994203</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2014-01-07</td>\n      <td>0.994872</td>\n      <td>0.992509</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2014-01-08</td>\n      <td>0.992185</td>\n      <td>0.987730</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2589</th>\n      <td>2023-12-22</td>\n      <td>1.003994</td>\n      <td>1.013788</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2590</th>\n      <td>2023-12-26</td>\n      <td>1.014441</td>\n      <td>1.014900</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2591</th>\n      <td>2023-12-27</td>\n      <td>1.004676</td>\n      <td>1.014155</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2592</th>\n      <td>2023-12-28</td>\n      <td>1.000828</td>\n      <td>1.008533</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2593</th>\n      <td>2023-12-29</td>\n      <td>1.000557</td>\n      <td>1.005337</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2594 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the average daily growth_7d for the LARGEST_STOCKS group vs. the LARGE_STOCKS group.\n",
    "\n",
    "pivot_table['more_new'] = np.where(pivot_table['NEW'] > pivot_table['OLD'], 1, 0)\n",
    "pivot_table"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T00:27:04.811099Z",
     "start_time": "2024-05-17T00:27:04.797397Z"
    }
   },
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "more_new\n0    1384\n1    1210\nName: count, dtype: int64"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the number of days when the LARGE GROUP (new smaller stocks) outperforms the LARGEST GROUP, divide it by the total number of trading days (which should be 2595 days), and convert it to a percentage (closest INTEGER value).\n",
    "\n",
    "pivot_table.more_new.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T00:27:48.356514Z",
     "start_time": "2024-05-17T00:27:48.340158Z"
    }
   },
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "more_new\n0    0.533539\n1    0.466461\nName: count, dtype: float64"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_table.more_new.value_counts() / len(pivot_table)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T00:27:50.209247Z",
     "start_time": "2024-05-17T00:27:50.203181Z"
    }
   },
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "more_new\n0    53.0\n1    47.0\nName: count, dtype: float64"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(100*pivot_table.more_new.value_counts()/len(pivot_table))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T00:29:51.907968Z",
     "start_time": "2024-05-17T00:29:51.892383Z"
    }
   },
   "execution_count": 51
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Question 4: Trying Another Technical Indicators strategy\n",
    "What's the total gross profit (in THOUSANDS of $) you'll get from trading on CCI (no fees assumption)?\n",
    "\n",
    "First, run the entire Colab to obtain the full DataFrame of data (after [Code Snippet 9]), and truncate it to the last full 10 years of data (2014-01-01 to 2023-12-31). If you encounter any difficulties running the Colab - you can download it using this link.\n",
    "\n",
    "Let's assume you've learned about the awesome CCI indicator (Commodity Channel Index), and decided to use only it for your operations.\n",
    "\n",
    "You defined the \"defensive\" value of a high threshould of 200, and you trade only on Fridays (Date.dt.dayofweek()==4).\n",
    "\n",
    "That is, every time you see that CCI is >200 for any stock (out of those 33), you'll invest $1000 (each record when CCI>200) at Adj.Close price and hold it for 1 week (5 trading days) in order to sell at the Adj. Close price.\n",
    "\n",
    "What's the expected gross profit (no fees) that you get in THOUSANDS $ (closest integer value) over many operations in 10 years? One operation calculations: if you invested $1000 and received $1010 in 5 days - you add $10 to gross profit, if you received $980 - add -$20 to gross profit. You need to sum these results over all trades (460 times in 10 years)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
